<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      ResNet | cheny 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="cheny">
    
    

    <meta name="description" content="原文最近在统计的深度学习高引用论文中，何恺明团队的ResNet排第一，引用已过万，可见其对深度学习发展影响，由于最近看SR论文中，基本网络都有用到Resnet结构，于是特写篇博客来复习巩固一下，同时对CNN的一些基本问题进行研究。">
<meta property="og:type" content="article">
<meta property="og:title" content="ResNet | cheny">
<meta property="og:url" content="http://yoursite.com/2018/08/13/ResNet/index.html">
<meta property="og:site_name" content="cheny">
<meta property="og:description" content="原文最近在统计的深度学习高引用论文中，何恺明团队的ResNet排第一，引用已过万，可见其对深度学习发展影响，由于最近看SR论文中，基本网络都有用到Resnet结构，于是特写篇博客来复习巩固一下，同时对CNN的一些基本问题进行研究。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/images/Res.jpg">
<meta property="og:image" content="http://yoursite.com/images/densenet1.png">
<meta property="og:image" content="http://yoursite.com/images/densenet2.png">
<meta property="og:updated_time" content="2018-08-13T12:01:29.510Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ResNet | cheny">
<meta name="twitter:description" content="原文最近在统计的深度学习高引用论文中，何恺明团队的ResNet排第一，引用已过万，可见其对深度学习发展影响，由于最近看SR论文中，基本网络都有用到Resnet结构，于是特写篇博客来复习巩固一下，同时对CNN的一些基本问题进行研究。">
<meta name="twitter:image" content="http://yoursite.com/images/Res.jpg">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css">

</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">cheny</a></h1>
        <hr class="panel-cover__divider" />

        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">ResNet</h1>

    

    <div class="post-meta">
      <time datetime="2018-08-13" class="post-meta__date date">2018-08-13</time> 

      <span class="post-meta__tags tags">

          

          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <p><a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">原文</a><br>最近在统计的深度学习高引用论文中，何恺明团队的ResNet排第一，引用已过万，可见其对深度学习发展影响，由于最近看SR论文中，基本网络都有用到Resnet结构，于是特写篇博客来复习巩固一下，同时对CNN的一些基本问题进行研究。<br><a id="more"></a></p>
<h2 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1.网络结构"></a>1.网络结构</h2><p><img src="/images/Res.jpg" alt=""><br>ResNet相对于传统卷积神经网络其实只是增加了skip connection，即如上图所示。</p>
<h2 id="2-作用"><a href="#2-作用" class="headerlink" title="2.作用"></a>2.作用</h2><p>ResNet前言提到了其实为了解决神经网络随着层数增加，难以训练、泛化能力不好的问题，随着层数逐渐增加，在梯度反向传播的过程中，必定会产生梯度消失，导致神经网络难以优化，而残差神经网络则通过skip connection将梯度直接向后传递，从而解决了梯度消失的问题，因此通过Residual Block也可以设计更深的卷积神经网络。</p>
<h2 id="3-拓展"><a href="#3-拓展" class="headerlink" title="3.拓展"></a>3.拓展</h2><p>我看的第一篇深度学习论文便是DenseNet，它是基于ResNet的思想的，只不过它更加疯狂，采用一种密集全连接，将所以层都连接起来。<br><img src="/images/densenet1.png" alt=""><br><img src="/images/densenet2.png" alt=""><br>如图每个Dense Block都采用密集全连接。<br>当时作者提出了一种类似于 Dropout 的方法来改进ResNet。发现在训练过程中的每一步都随机地「扔掉」（drop）一些层，可以显著的提高 ResNet 的泛化性能。这个方法的成功至少带给我们两点启发:<br>1.首先，它说明了神经网络其实并不一定要是一个递进层级结构，也就是说网络中的某一层可以不仅仅依赖于紧邻的上一层的特征，而可以依赖于更前面层学习的特征。想像一下在随机深度网络中，当第 l 层被扔掉之后，第 l+1 层就被直接连到了第 l-1 层；当第 2 到了第 l 层都被扔掉之后，第 l+1 层就直接用到了第 1 层的特征。因此，随机深度网络其实可以看成一个具有随机密集连接的 DenseNet。<br>2.其次，我们在训练的过程中随机扔掉很多层也不会破坏算法的收敛，说明了 ResNet 具有比较明显的冗余性，网络中的每一层都只提取了很少的特征（即所谓的残差）。实际上，我们将训练好的 ResNet 随机的去掉几层，对网络的预测结果也不会产生太大的影响。既然每一层学习的特征这么少，能不能降低它的计算量来减小冗余呢？<br>DenseNet 的设计正是基于以上两点观察。我们让网络中的每一层都直接与其前面层相连，实现特征的重复利用；同时把网络的每一层设计得特别「窄」，即只学习非常少的特征图（最极端情况就是每一层只学习一个特征图），达到降低冗余性的目的。</p>

  </section>

  <section class="post-comments">

    <!-- 将评论系统（例如Disqus、多说、友言、畅言等）提供的代码片段粘贴在这里 -->
    
</section>


</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2014-2015. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a></span>
    
</footer>
        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

</body>
</html>
