<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      tensorflow-一元线性模型 | cheny 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="cheny">
    
    

    <meta name="description" content="数据见deep learning，这是一个一元输入、一元输出的线性模型，下面是具体实现过程：">
<meta property="og:type" content="article">
<meta property="og:title" content="tensorflow-一元线性模型 | cheny">
<meta property="og:url" content="http://yoursite.com/2018/08/06/My-New-Post/index.html">
<meta property="og:site_name" content="cheny">
<meta property="og:description" content="数据见deep learning，这是一个一元输入、一元输出的线性模型，下面是具体实现过程：">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-08-10T06:56:00.597Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="tensorflow-一元线性模型 | cheny">
<meta name="twitter:description" content="数据见deep learning，这是一个一元输入、一元输出的线性模型，下面是具体实现过程：">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css">

</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">cheny</a></h1>
        <hr class="panel-cover__divider" />

        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">tensorflow-一元线性模型</h1>

    

    <div class="post-meta">
      <time datetime="2018-08-06" class="post-meta__date date">2018-08-06</time> 

      <span class="post-meta__tags tags">

          

          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <p>数据见<a href="http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=DeepLearning&amp;doc=exercises/ex2/ex2.html" target="_blank" rel="noopener">deep learning</a>，这是一个一元输入、一元输出的线性模型，下面是具体实现过程：<br><a id="more"></a></p>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"><span class="comment">#通过numpy.loadtxt()函数解析当前目录数据x.y</span></span><br><span class="line">x_data=np.loadtxt(<span class="string">'./ex2x.dat'</span>)</span><br><span class="line">y_data=np.loadtxt(<span class="string">'./ex2y.dat'</span>)</span><br><span class="line"><span class="comment">#设置线性函数参数W、b</span></span><br><span class="line"><span class="comment">#W初始化为均匀随机数</span></span><br><span class="line">W=tf.Variable(tf.random_uniform([1],-1.0,1.0))</span><br><span class="line"><span class="comment">#b初始化为0</span></span><br><span class="line">b=tf.Variable(tf.zeros([1]))</span><br><span class="line"><span class="comment">#参数下输出为y_</span></span><br><span class="line">y_=W*x_data+b</span><br><span class="line"><span class="comment">#设置损失函数 </span></span><br><span class="line">loss=tf.reduce_mean(tf.square(y_data-y_))/2</span><br><span class="line"><span class="comment">#定义梯度下降优化器 设置学习率</span></span><br><span class="line">optimizer=tf.train.GradientDescentOptimizer(0.07)</span><br><span class="line"><span class="comment">#定义优化方法</span></span><br><span class="line">train=optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#会话执行图</span></span><br><span class="line">sess=tf.Session()</span><br><span class="line"><span class="comment">#初始化变量</span></span><br><span class="line">init=tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行梯度下降优化</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(1500):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    <span class="keyword">if</span> i%100==0:</span><br><span class="line">        <span class="built_in">print</span> sess.run(W),sess.run(b)</span><br></pre></td></tr></table></figure>
<h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[0.38659847] [0.07704204]</span><br><span class="line">[0.13098377] [0.41046652]</span><br><span class="line">[0.09381685] [0.5863949]</span><br><span class="line">[0.07821415] [0.67140335]</span><br><span class="line">[0.07077159] [0.71229064]</span><br><span class="line">[0.06719442] [0.73195165]</span><br><span class="line">[0.06547432] [0.7414059]</span><br><span class="line">[0.06464729] [0.7459518]</span><br><span class="line">[0.06424948] [0.7481382]</span><br><span class="line">[0.06405827] [0.7491891]</span><br><span class="line">[0.06396635] [0.74969447]</span><br><span class="line">[0.06392214] [0.74993736]</span><br><span class="line">[0.06390087] [0.75005424]</span><br><span class="line">[0.06389064] [0.7501105]</span><br><span class="line">[0.0638857] [0.7501377]</span><br><span class="line"></span><br><span class="line">当然实际过程并没有这么顺利，当我令loss=tf.reduce_mean(tf.square(y_data-y_))，学习率设为0.07时,会出现如下结果：</span><br><span class="line">[0.48159832] [0.08058839]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br><span class="line">[nan] [nan]</span><br></pre></td></tr></table></figure>
<h3 id="Disscussion"><a href="#Disscussion" class="headerlink" title="Disscussion"></a>Disscussion</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">但是调小学习率为0.01时却又可以收敛,由此可以看出产生nan的原因是由于learning rate 过大，那么为什么将loss除2以后就又收敛了呢，这说明learning rate 其实是与loss相对应的；之前让我百思不得其解的是，为什么学习率为0.07，而loss不除以2的时候会出现nan，但是当把loss除以2的时候就收敛了，后来发现学习率其实是乘以loss的梯度的，当loss除2的时候,相当于同等条件下学习率除2.至于产生nan的详细解释，我觉得是学习率过大，导致梯度爆炸，超出数值范围，于是显示为 nan，对于这个问题我也欢迎大家一起讨论，因为的确还存在一些疑问。</span><br></pre></td></tr></table></figure>

  </section>

  <section class="post-comments">

    <!-- 将评论系统（例如Disqus、多说、友言、畅言等）提供的代码片段粘贴在这里 -->
    
</section>


</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2014-2015. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a></span>
    
</footer>
        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

</body>
</html>
